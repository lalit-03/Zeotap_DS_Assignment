{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    \"\"\"\n",
    "    Load and prepare the dataset for analysis\n",
    "    \"\"\"\n",
    "    # Load datasets\n",
    "    customers = pd.read_csv('data/Customers.csv')\n",
    "    products = pd.read_csv('data/Products.csv')\n",
    "    transactions = pd.read_csv('data/Transactions.csv')\n",
    "    \n",
    "    # Convert dates to datetime\n",
    "    customers['SignupDate'] = pd.to_datetime(customers['SignupDate'])\n",
    "    transactions['TransactionDate'] = pd.to_datetime(transactions['TransactionDate'])\n",
    "    \n",
    "    return customers, products, transactions\n",
    "\n",
    "\n",
    "def create_customer_features(customers, transactions, products):\n",
    "\n",
    "    # RFM Analysis\n",
    "    \n",
    "    # Recency\n",
    "    max_date = transactions['TransactionDate'].max()\n",
    "    last_purchase = transactions.groupby('CustomerID')['TransactionDate'].max()\n",
    "    recency = (max_date - last_purchase).dt.days\n",
    "    \n",
    "    # Frequency\n",
    "    frequency = transactions.groupby('CustomerID').size()\n",
    "    \n",
    "    # Monetary\n",
    "    monetary = transactions.groupby('CustomerID')['TotalValue'].sum()\n",
    "    \n",
    "    # Average order value\n",
    "    avg_order = transactions.groupby('CustomerID')['TotalValue'].mean()\n",
    "    \n",
    "    # Region (simple binary features)\n",
    "    region_dummies = pd.get_dummies(customers.set_index('CustomerID')['Region'])\n",
    "    \n",
    "    # Combine features\n",
    "    features = pd.DataFrame({\n",
    "        'Recency': recency,\n",
    "        'Frequency': frequency,\n",
    "        'Monetary': monetary,\n",
    "        'AvgOrderValue': avg_order\n",
    "    })\n",
    "    \n",
    "    # Add region\n",
    "    features = features.join(region_dummies)\n",
    "    \n",
    "    # Reset index to make CustomerID a column\n",
    "    features = features.reset_index()\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def calculate_similarity_scores(customer_features):\n",
    "    \"\"\"\n",
    "    Calculate similarity scores between customers\n",
    "    \"\"\"\n",
    "    # Separate CustomerID and features\n",
    "    customer_ids = customer_features['CustomerID']\n",
    "    features = customer_features.drop('CustomerID', axis=1)\n",
    "    feature_names = features.columns\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity_matrix = cosine_similarity(scaled_features)\n",
    "    \n",
    "    return similarity_matrix, customer_ids\n",
    "\n",
    "def get_top_lookalikes(customer_id, similarity_matrix, customer_ids, n=3):\n",
    "    \"\"\"\n",
    "    Get top n lookalike customers for a given customer\n",
    "    \"\"\"\n",
    "    customer_index = customer_ids[customer_ids == customer_id].index[0]\n",
    "    customer_similarities = similarity_matrix[customer_index]\n",
    "    \n",
    "    # Get indices of top n similar customers (excluding self)\n",
    "    similar_indices = np.argsort(customer_similarities)[::-1][1:n+1]\n",
    "    \n",
    "    # Create recommendations with similarity scores\n",
    "    recommendations = []\n",
    "    for idx in similar_indices:\n",
    "        recommendations.append({\n",
    "            'CustomerID': customer_ids.iloc[idx],\n",
    "            'SimilarityScore': customer_similarities[idx]\n",
    "        })\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Load and prepare data\n",
    "customers, products, transactions = load_and_prepare_data()\n",
    "\n",
    "# Create customer features\n",
    "customer_features = create_customer_features(customers, transactions, products)\n",
    "\n",
    "# Calculate similarity scores\n",
    "similarity_matrix, customer_ids = calculate_similarity_scores(customer_features)\n",
    "\n",
    "# Generate lookalikes for first 20 customers\n",
    "lookalike_results = {}\n",
    "\n",
    "for customer_id in customers['CustomerID'][:20]:  # First 20 customers\n",
    "    recommendations = get_top_lookalikes(customer_id, similarity_matrix, customer_ids)\n",
    "    lookalike_results[customer_id] = recommendations\n",
    "\n",
    "# Create output DataFrame\n",
    "output_rows = []\n",
    "for customer_id, recs in lookalike_results.items():\n",
    "    row = {\n",
    "        'CustomerID': customer_id,\n",
    "        'Lookalikes': str([f\"{rec['CustomerID']}:{rec['SimilarityScore']:.3f}\" for rec in recs])\n",
    "    }\n",
    "    output_rows.append(row)\n",
    "\n",
    "output_df = pd.DataFrame(output_rows)\n",
    "\n",
    "# Save to CSV\n",
    "output_df.to_csv('LalitChandra_Routhu_Lookalike.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
